{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "coral-renewal",
   "metadata": {},
   "source": [
    "#  <center> Taller  de Aprendizaje Automático </center>\n",
    "##  <center> Taller 1: Titanic  </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congressional-personal",
   "metadata": {},
   "source": [
    "En esta actividad se trabajará con el dataset [Titanic](https://www.kaggle.com/c/titanic/overview) disponible en Kaggle. El objetivo es predecir si un pasajero sobrevivirá a partir de atributos personales. La descripción de los atributos se encuentra en la misma [página](https://www.kaggle.com/c/titanic/data) en que se pueden bajar los datos. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organic-shelf",
   "metadata": {},
   "source": [
    "## Objetivos\n",
    " - Abordar un problema de aprendizaje automático de punta a punta\n",
    " - Familiarizarse con la biblioteca **pandas** para levantar y explorar los datos\n",
    " - Familiarizarse con los **pipelines** de **scikit-learn** como una forma de resolver un problema en forma ordenada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "common-destiny",
   "metadata": {},
   "source": [
    "## Formas de trabajo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-gallery",
   "metadata": {},
   "source": [
    "### Opción 1: Trabajar localmente\n",
    "\n",
    "Descargar los datos en su máquina personal y trabajar en su propio ambiente de desarrollo. Ej: **conda environment**.  \n",
    "\n",
    "*conda create -n TAA-py38 python=3.8*  \n",
    "*pip install numpy matplotlib pandas scikit-learn notebook*     \n",
    "*conda activate TAA-py38*    \n",
    "*jupyter-notebook*    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fantastic-happiness",
   "metadata": {},
   "source": [
    "Los paquetes faltantes se pueden instalar desde el notebook haciendo:     \n",
    "*!pip install paquete_faltante*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lined-sport",
   "metadata": {},
   "source": [
    "### Opción 2:  Trabajar en *Colab*. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lined-candle",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/TAA-fing/TAA-2021/blob/main/taller1_titanic.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Ejecutar en Google Colab</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expensive-jewel",
   "metadata": {},
   "source": [
    "Se puede trabajar en Google Colab. Para ello es necesario contar con una cuenta de **google drive** y ejecutar un notebook almacenado en dicha cuenta. De lo contrario, no se conservarán los cambios realizados en la sesión. En caso de ya contar con una cuenta, se puede abrir el notebook y luego ir a *Archivo-->Guardar una copia en drive*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "committed-quarterly",
   "metadata": {},
   "source": [
    "En caso de estar trabajando desde un notebook en Colab, la siguiente celda realiza la configuración necesaria para obtener datos desde la plataforma Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "mediterranean-sullivan",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2fb99448d479>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# El siguiente archivo solicitado es para habilitar la API de Kaggle en el entorno que está trabajando.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from google.colab import files\n",
    "\n",
    "# El siguiente archivo solicitado es para habilitar la API de Kaggle en el entorno que está trabajando.\n",
    "# Este archivo se descarga entrando a su perfíl de Kaggle, en la sección API, presionando donde dice: Create New API Token\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
    "      name=fn, length=len(uploaded[fn])))\n",
    "  \n",
    "#Then move kaggle.json into the folder where the API expects to find it.\n",
    "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stretch-sunglasses",
   "metadata": {},
   "source": [
    "Una vez guardado el *token* se pueden descargar los datos, en este caso se bajarán los datos de la competencia *titanic*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "chicken-token",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/guillermo/.kaggle/kaggle.json'\n",
      "Downloading titanic.zip to /home/guillermo/gitlab/taller-de-aprendizaje-automatico/talleres/Taller1\n",
      "  0%|                                               | 0.00/34.1k [00:00<?, ?B/s]\n",
      "100%|██████████████████████████████████████| 34.1k/34.1k [00:00<00:00, 1.94MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions download -c titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitted-victor",
   "metadata": {},
   "source": [
    "### Parte 1 - Carga de datos\n",
    "\n",
    "Descargar los datos y levantar el conjunto de entrenamiento utilizando el método `read_csv()` de la biblioteca *pandas*. Luego ejecutar los métodos `head()`, `info()` y `describe()` de *pandas*. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfactory-washington",
   "metadata": {},
   "source": [
    "### Parte 2 - Exploración con pandas\n",
    "\n",
    "Asegúrese que puede responder las siguientes preguntas:      \n",
    "    - ¿Cuál es el atributo que se quiere predecir?     \n",
    "    - ¿Cuáles son los atributos numéricos y cuáles los categóricos?     \n",
    "    - ¿Cuál es el porcentaje de pasajeros del conjunto de entrenamiento que sobrevivió?      \n",
    "    - ¿Cuál es el porcentaje de mujeres? ¿Y de hombres?        \n",
    "    - ¿Hay datos faltantes?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordered-turkey",
   "metadata": {},
   "source": [
    "### Parte 3 - Correlaciones\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driving-raise",
   "metadata": {},
   "source": [
    "Comente qué factores tuvieron mayor incidencia en la supervivencia o no de un pasajero. Se sugiere utilizar el método `corr()` de *pandas* así como [métodos de visualización](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.html). Para graficar con *pandas* es necesario importar *matplotlib*. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sublime-blond",
   "metadata": {},
   "source": [
    "### Parte 4 - Un primer pipeline\n",
    "\n",
    "Construir un *pipeline* que realice el preprocesamiento de los datos necesario para que éstos puedan ser utilizados por un clasificador de *sklearn*. Dicho preprocesamiento deberá en primera instancia realizar las siguientes tareas:\n",
    "\n",
    "1. Descartar los atributos *Cabin*, *Name* y *Ticket*.\n",
    "2. Relllenar datos faltantes con algún criterio elegido"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corresponding-jefferson",
   "metadata": {},
   "source": [
    "### Parte 5 - Pipeline que usa un único atributo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peaceful-statistics",
   "metadata": {},
   "source": [
    "Realizar un pipeline que se quede como único atributo el género del pasajero. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agricultural-median",
   "metadata": {},
   "source": [
    "### Parte 6 - Clasificador SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordered-network",
   "metadata": {},
   "source": [
    "Entrenar para cada uno de los pipelines de preprocesamiento un clasificador *SVM linear* con parámetors por defecto y estimar el error mediante validación cruzada 5-folds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greenhouse-westminster",
   "metadata": {},
   "source": [
    "### Parte 7: Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "written-benchmark",
   "metadata": {},
   "source": [
    "Utilizar *Grid Search* para encontrar el valor óptimo del parámetro *C* del clasificador *SVM* generado con el *pipeline* de la parte 4. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acute-savings",
   "metadata": {},
   "source": [
    "### Parte 8: Guardar modelos\n",
    "\n",
    "Es posible que la parte anterior haya demorado bastante en correr. Asegúrese de guardar el modelo que obtuvo. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consistent-biodiversity",
   "metadata": {},
   "source": [
    "### Parte 9: Generar predicciones en conjunto de test\n",
    "\n",
    "Levante el modelo guardado en la parte anterior y genere las predicciones con el conjunto de test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressed-reading",
   "metadata": {},
   "source": [
    "### Parte 10: Generar Kaggle Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worse-clarity",
   "metadata": {},
   "source": [
    "Dado que cuenta con un primer modelo entrenado está en condiciones de subir sus predicciones a la plataforma Kaggle. Si desea hacerlo [aquí](https://www.kaggle.com/alexisbcook/titanic-tutorial) encontrará un ejemplo. De todas formas, lo alentamos a trabajar en la siguiente parte para generar un mejor modelo. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "horizontal-cambodia",
   "metadata": {},
   "source": [
    "### Parte 11: Un mejor pipeline   \n",
    "\n",
    "Generar un nuevo pipeline y evaluar si éste genera un mejor clasificador. Algunas de las opciones que se pueden explorar son las siguientes:\n",
    "* ¿Pclass como dato numérico, ordinal o categórico?   \n",
    "* ¿Escalar los atributos numéricos sirve? ¿Qué escalado?   \n",
    "* Generación y/o sustitución de características:   \n",
    "    - Reemplazar *SibSp* y *Parch* por la suma     \n",
    "    - Discretizar algún atributo numérico, por ejemplo la edad.\n",
    "* Constuir un pipeline que permita determinar automáticamente qué grupo de características utilizar y qué estrategia seguir para lidiar con datos faltantes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
